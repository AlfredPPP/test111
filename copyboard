import requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# 创建一个 Session 对象来管理请求
session = requests.Session()

# 设置 User-Agent，模仿 Scrapy 的默认行为
session.headers.update({
    "User-Agent": "Scrapy/2.9.0 (+https://scrapy.org)"
})

# 自动处理重定向和重试策略
retry_strategy = Retry(
    total=3,  # 重试次数
    backoff_factor=0.3,  # 每次重试间隔时间的倍数
    status_forcelist=[429, 500, 502, 503, 504],  # 遇到这些状态码会重试
)
adapter = HTTPAdapter(max_retries=retry_strategy)
session.mount("http://", adapter)
session.mount("https://", adapter)

# 访问目标网站
url = "https://example.com"  # 替换为你的目标网站地址
response = session.get(url)

# 检查响应
if response.status_code == 200:
    print("成功获取响应内容：")
    print(response.text)  # 输出页面内容
else:
    print(f"请求失败，状态码: {response.status_code}")